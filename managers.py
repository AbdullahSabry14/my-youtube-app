# from google import genai

# c = genai.Client(api_key="AIzaSyAZBWQyV70RdE2FlPlwIRYbLkjCBdi2m40")

# re = c.models.generate_content(
#     model="gemini-3-flash-preview",
#     contents="Ø§Ù†Ø§ Ø§Ø¨Ùˆ Ø§Ù„ØµØ¨Ø±ÙŠ Ù…Ø¨Ø±Ù…Ø¬ Ø§Ø­ÙØ¸Ù†ÙŠ ÙŠØ§ Ø¹Ø³Ù„"
# )
# print(re.text)



import sys
import io
import os

if sys.stdout is None or sys.stderr is None:
    # Ø¨Ø¯Ø§Ù„ devnull Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ®Ù†Ù‚ Ø§Ù„Ù€ PipesØŒ Ø¨Ù†Ø³ØªØ®Ø¯Ù… StringIO
    # Ù‡Ø°Ø§ Ø¨ÙŠØ®Ù„ÙŠ MoviePy ØªÙØªÙƒØ± Ø¥Ù† ÙÙŠ Terminal Ø´ØºØ§Ù„ ÙˆÙ…Ø§ Ø¨ØªØ¹Ù…Ù„ Crash
    sys.stdout = io.StringIO()
    sys.stderr = io.StringIO()
else:
    try:
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    except:
        pass
    
import pyi_splash
import requests
from PIL import Image
from tqdm import tqdm
from urllib.parse import quote_plus
import time 
from requests.exceptions import ReadTimeout, ConnectionError, RequestException
import re
import glob
import math
from moviepy.editor import *
import numpy as np
import customtkinter as ctk
import tkinter as tk
from plyer import notification
import threading
from elevenlabs.client import ElevenLabs
from elevenlabs import save
from google import genai

pyi_splash.close()

ctk.set_appearance_mode("Dark")

lolo = ctk.CTk()
lolo.title("ØµØ§Ù†Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª")
lolo.geometry("410x180")
lolo.resizable(False, False)

key1 = "sk_663aea92de9cc1d28fbf892accf52374f634a5dde791d2c0"
key2 = "AIzaSyAZBWQyV70RdE2FlPlwIRYbLkjCBdi2m40"

FINAL_RESOLUTION = (720, 1280)
ZOOM_FACTOR = 1.25
CLIP_DURATION = 2.5
elevenlabs = ElevenLabs(api_key=key1)

FONT_PATH = "Cairo-Black.ttf"

def cleanup_directories():

    audio_files = glob.glob(os.path.join("Audio", "*.mp3"))
    for f in audio_files:
        try:
            time.sleep(0.1) 
            os.remove(f)
        except OSError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„ØµÙˆØª {f}: {e}")

    image_files = glob.glob(os.path.join("Images", "*.jpg"))
    for f in image_files:
        try:
            time.sleep(0.1) 
            os.remove(f)
        except OSError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„ØµÙˆØ±Ø© {f}: {e}")

    os.makedirs("Audio", exist_ok=True)
    os.makedirs("Images", exist_ok=True)

class script_writing :
    def __init__(self, title):
        self.titlei = title
        self.script_content = None

    def script(self) :
        popo = f"""Ø£Ù†Øª "ÙƒØ§ØªØ¨ Ø³ÙƒØ±ÙŠØ¨Øª ÙÙŠØ¯ÙŠÙˆ Ù‚ØµÙŠØ± (Shorts) Ù…Ø­ØªØ±Ù"ØŒ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ù…Ø¤Ø«Ø± ÙˆØ³Ø±ÙŠØ¹ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ØŒ Ù…Ù„ØªØ²Ù… ØªÙ…Ø§Ù…Ø§Ù‹ Ø¨Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„ØµØ§Ø±Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:
**Ø§Ù„Ù…Ù‡Ù…Ø©:** ØµÙŠØ§ØºØ© Ø³ÙƒØ±ÙŠØ¨Øª Ø®Ø§Ù… ÙˆÙ…ÙˆØµÙˆÙ„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: [{self.titlei}].
**Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„ØµØ§Ø±Ù…Ø© (Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©):**
1. **Ø§Ù„Ø¹Ø¯Ø¯:** ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Ø§ØªØ¬ 50 ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø·. ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø¯Ù‚Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.
2. **Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:** Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ… Ø¯Ø§Ø®Ù„ÙŠØ© (Ù…Ø«Ù„ Ø§Ù„ÙØ§ØµÙ„Ø©ØŒ Ø§Ù„Ù†Ù‚Ø·Ø©ØŒ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ù…Ù†Ù‚ÙˆØ·Ø©). ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Øµ Ø³Ù„Ø³Ù„Ø© Ù…ØªØµÙ„Ø© ÙˆØ®Ø§Ù…Ø§Ù‹ ØªÙ…Ø§Ù…Ø§Ù‹.
3. **Ø§Ù„Ø®Ø·Ø§Ù:** ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¨Ø¯Ø£ Ø§Ù„Ù†Øµ Ø¨Ø®Ø·Ø§Ù Ù‚ÙˆÙŠ ÙˆÙ…Ø«ÙŠØ± Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 10 ÙƒÙ„Ù…Ø§Øª Ù„Ø¬Ø°Ø¨ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ ÙÙˆØ±Ø§Ù‹.
4. **Ø§Ù„Ù‡ÙŠÙƒÙ„:** ØµÙ„Ø¨ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø³Ø±ÙŠØ¹Ø§Ù‹ ÙˆÙ‚ÙˆÙŠØ§Ù‹ ÙˆÙ…ÙØ±ÙƒÙ‘Ø²Ø§Ù‹ ÙˆÙŠÙ†ØªÙ‡ÙŠ Ø¯ÙˆÙ† Ø®Ø§ØªÙ…Ø© ØªÙ‚Ù„ÙŠØ¯ÙŠØ©.
5. Ù„Ù„Ù…Ø±Ø© Ø§Ù„Ù…Ù„ÙŠÙˆÙ† ØªØ£ÙƒØ¯ ÙƒØ«ÙŠØ± Ø§Ù†Ù‡ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ØµØºÙŠØ± Ù„ÙŠÙƒÙˆÙ† Ø­ÙˆØ§Ù„ÙŠ Ù†ØµÙ Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙŠØ£ØªÙŠ 50 ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù„Ø§ Ø£Ù‚Ù„ ÙˆÙ„Ø§ Ø£ÙƒØ«Ø± Ø­ØªÙ‰ Ù„Ø§ ÙŠØ®Ø±Ù‘Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø±ÙƒÙ‘Ø² ÙˆØ£Ø¹Ø¯ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø£Ù„Ù Ù…Ø±Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø©.
6. Ù„Ø§ ØªÙƒØªØ¨ Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ Ù…ÙƒÙˆÙ†Ø© Ù…Ù† ÙƒÙ„Ù…ØªÙŠÙ† Ø£Ùˆ Ø«Ù„Ø§Ø« ÙÙ‡Ø°Ø§ ÙŠØ²Ø¹Ø¬ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.
7. Ù„ÙŠÙƒÙˆÙ† Ù†ØµÙ Ø¯Ù‚ÙŠÙ‚Ø© Ø«Ù„Ø§Ø«ÙŠÙ† Ø«Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙˆØ¥Ù„Ø§ ÙŠØ®Ø±Ù‘Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙƒÙ„Ù‡.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ù…Ù† ÙÙ‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…ØªØµÙ„Ø© Ù„Ø§ ØªÙØµÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù…Ù„ Ø¨Ø£Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙ„Ø§ Ø¨ÙÙˆØ§ØµÙ„ ÙƒØ¨ÙŠØ±Ø©
ÙˆÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ØµÙ„ÙŠ ÙˆØ­Ù‚ÙŠÙ‚ÙŠ Ù…Ù†Ùƒ Ø¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ§Ø¶Ø­ ÙˆØ³Ù„Ø³ ÙˆÙ…ØªØ±Ø§Ø¨Ø· Ø¨Ø­ÙŠØ« ØªÙ†ØªÙ‚Ù„ Ø§Ù„ÙÙƒØ±Ø© Ø¨Ø§Ù†Ø³ÙŠØ§Ø¨ Ø·Ø¨ÙŠØ¹ÙŠ
Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆØ¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ØªØ´Ø¨Ù‡ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨
Ù„Ø§ ØªØ¶Ø¹ Ù…Ù‚Ø¯Ù…Ø§Øª Ø£Ùˆ Ù†Ù‡Ø§ÙŠØ§Øª Ù…Ø«Ù„ Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø£Ùˆ ÙÙŠ Ø§Ù„Ø®ØªØ§Ù…
Ù„Ø§ ØªÙ†Ø³Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ø¨Ø§Ù„Ø²Ø¨Ø· Ù†ØµÙ Ø¯Ù‚ÙŠÙ‚Ø© Ø£ÙŠ Ø¨Ø§Ù„Ø²Ø¨Ø· 30 Ø«Ø§Ù†ÙŠØ© ÙˆÙ„Ø§Ø²Ù… ÙƒÙ„ Ø¬Ù…Ù„Ø© Ù…Ù†Ø·Ù‚ÙŠØ© Ø§Ù‚Ø¯Ø± Ø§Ø³ÙˆÙŠ Ù…Ù†Ù‡Ø§ ØµÙˆØ±Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ÙƒÙ„Ø§Ù…
Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ù€ 50 ÙƒÙ„Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙ‚Ø· 50 ÙƒÙ„Ù…Ø© Ù„Ø§ Ø£Ù‚Ù„ ÙˆÙ„Ø§ Ø£Ø²ÙŠØ¯ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù† Ø¨Ø´Ø±Ø· Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª 30 Ø«Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ø²Ø¨Ø·"""

        try:
            c = genai.Client(api_key=key2)
            re = c.models.generate_content(
                model="gemini-3-flash-preview",
                contents=popo
            )
            summary_content = re.text
            self.script_content = summary_content
            word_count = len(summary_content.split())
            print("--------------------------------------------------")
            print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø¨Ù†Ø¬Ø§Ø­ (Ù…ÙˆØ¶ÙˆØ¹: {self.titlei})")
            print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ø§ØªØ¬: {word_count}")
            print("--------------------------------------------------")
            print(f"Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª: {summary_content}\n")

            return summary_content

        except Exception as e:
            raise Exception(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø£Ùˆ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¹Ø¨Ø± Ø¬ÙŠÙ…Ø§ÙŠÙ†: {e}")

class script_division(script_writing) :
    def __init__(self, script_obj):
        self.script_content = script_obj.script_content
        self.unvocalized_script = None
        self.vecalized_script = None

    def divisio1(self) :
        popo = f"""Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø®Ø§Ù… ÙˆØ§Ù„Ù…ÙˆØµÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø¬Ù…Ù„ ÙƒØ§Ù…Ù„Ø© ÙˆØ·Ø¨ÙŠØ¹ÙŠØ©.
**Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„ØµØ§Ø±Ù…Ø© (Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©):**
1. Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© (Ù…Ø«Ù„ Ø§Ù„Ù†Ù‚Ø·Ø© Ø£Ùˆ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ù…Ù†Ù‚ÙˆØ·Ø© Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…) Ù„Ø¥Ù†Ù‡Ø§Ø¡ ÙƒÙ„ Ø¬Ù…Ù„Ø©.
2. Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† **Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø³Ù… ÙÙ‚Ø· ÙƒÙ†Øµ Ø®Ø§Ù… Ù…ÙˆØµÙˆÙ„ ÙˆØ§Ø­Ø¯**.
3. **Ù…Ù…Ù†ÙˆØ¹ Ø¨ØªØ§ØªØ§Ù‹** Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„ (1. 2. 3...) Ø£Ùˆ Ø£ÙŠ Ù…Ù‚Ø¯Ù…Ø§Øª Ø£Ùˆ Ø´Ø±ÙˆØ­Ø§Øª Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø£Ùˆ Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ù‚Ø¨Ù„ Ø£Ùˆ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ù‚Ø³Ù…Ø©.
4. Ù„Ø§ ØªÙ‚Ù… Ø¨ØªØ´ÙƒÙŠÙ„ Ø£ÙŠ ÙƒÙ„Ù…Ø©.
5. Ø§Ø­Ø°Ø± ÙˆØ§Ù‚ÙˆÙ„ Ù„Ø§ ØªÙ†Ø³Ù‰ Ø£Ù† ØªÙ‚Ø³Ù…Ù‡ ØªÙ‚Ø³ÙŠÙ…Ø§Øª Ù…Ù†Ø·Ù‚ÙŠØ© ÙˆØ´ÙˆÙ Ø§Ù„ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ù…Ù„ ÙˆÙ…Ø§ Ø¨Ø¹Ø¯Ù‡Ø§ Ù„ØªØ¹Ø±Ù Ø§ÙŠÙ† ØªÙ‚Øµ 
6. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø£ÙŠØ¶Ø§ Ù„Ø§ ØªØ·ÙˆÙ„ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù„Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„ÙˆØ§Ø­Ø¯ ÙƒØ«ÙŠØ±Ø§ ÙˆØ®Ù„ÙŠÙ‡Ù† Ø­ÙˆØ§Ù„ÙŠ 10 Ù…Ù‚Ø§Ø·Ø¹ Ù†ØµÙŠØ© 10 Ø§Ùˆ 9 11 Ø²ÙŠ Ù‡ÙŠÙƒ ÙŠØ¹Ù†ÙŠ Ù„Ø§ ØªØ·ÙˆÙ„ Ù†Øµ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ù†ØµÙŠ ÙˆÙ„Ø§ ØªÙ‚Ù„Ù„ ÙˆÙ„Ø§ ØªØ²ÙŠØ¯ Ù…Ù‚Ø§Ø·Ø¹ Ù†ØµÙŠØ© ÙŠØ¹Ù†ÙŠ Ø­ÙˆØ§Ù„ÙŠ 10 Ø§Ùˆ 8
7. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¹Ø¯Ù… ØªÙƒØ«ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù†ØµÙŠØ© Ù„Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„ÙˆØ§Ø­Ø¯ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ²Ù† Ø¹Ù† 10 Ù…Ù‚Ø§Ø·Ø¹ Ø£ÙƒØ«Ø± Ø§Ø´ÙŠ ÙÙ‚Ø· ÙˆØ·Ø¨Ø¹Ø§ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ù†ØµÙŠ Ø§Ù„ÙˆØ§Ø­Ø¯ Ù„Ø§ ØªÙ‚ØµØ±Ù‡ ÙƒØ«ÙŠØ± ÙˆÙ„Ø§ ÙŠÙƒÙ† Ø¹Ø¯Ø© ÙƒÙ„Ù…Ø§Øª Ù…Ø´ ÙŠØ¹Ù†ÙŠ ÙŠÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„ÙˆØ§Ø­Ø¯ ÙƒÙ„Ù…ØªÙŠÙ† Ø§Ùˆ Ø«Ù„Ø§Ø«Ø© Ù„Ø§ ÙŠØ²Ø¨Ø· ÙˆÙ„Ø§ Ø­ØªÙ‰ ÙƒÙ„Ù…Ø§Øª ÙƒØ«ÙŠØ± ÙÙŠ Ø§Ù„Ù…Ù†ØªØµÙ .ÙˆÙ‚Ø³Ù… Ù„ÙˆÙŠÙ†ØªØ§ ÙŠÙˆÙ‚Ù ÙˆÙˆÙŠÙ†ØªØ§ ÙŠØªØ­Ø±Ùƒ
Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø®Ø§Ù…: [{self.script_content}]."""
        c = genai.Client(api_key=key2)
        r = c.models.generate_content(
            model="gemini-3-flash-preview",
            contents=popo
        )
        summary_content = r.text
        clean = summary_content.replace(".", "#").replace("ØŒ", "#").replace("Ø›", "#").replace("ØŸ", "#").replace("\n", '#').replace("  ", " ")
        while "##" in clean:
            clean = clean.replace("##", "#")
        clean = re.sub(r'\s*\d+\.\s*', '', clean)
        telist = [text.strip() for text in clean.split("#") if text.strip()]
        final_list = []
        current_chunk = ""
        for item in telist:
            if not current_chunk:
                current_chunk = item
            else:
                if len(current_chunk.split()) < 5:
                    current_chunk += " " + item
                else:
                    final_list.append(current_chunk)
                    current_chunk = item
        if current_chunk:
            final_list.append(current_chunk)

        print("Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬:", final_list)
        self.unvocalized_script = final_list
        return final_list

    def division2(self) :
        if self.unvocalized_script is None :
            self.divisio1()

        raw_text_to_vocalize = " | ".join(self.unvocalized_script)

        print("\n...Ø¬Ø§Ø±ÙŠ ØªØ´ÙƒÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠ Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯ ÙˆÙ…ÙØ³Ø±ÙÙ‘Ø¹:")

        popo_segment = f"""Ø£Ù†Øª **Ø®Ø¨ÙŠØ± ØªØ´ÙƒÙŠÙ„ Ù„ØºÙˆÙŠ Ø¹Ø±Ø¨ÙŠ Ù…Ø·Ù„Ù‚ ÙˆÙ…ÙØ¯Ù‚Ù‚ ØµÙˆØªÙŠ Ù„Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù„ÙØ¸ÙŠØ©**ØŒ ÙˆÙ…Ù‡Ù…ØªÙƒ Ø§Ù„ÙˆØ­ÙŠØ¯Ø© ÙˆØ§Ù„Ø­ØµØ±ÙŠØ© Ù‡ÙŠ **Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠ ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„ØºÙˆÙŠØ§Ù‹ ÙˆØµÙˆØªÙŠØ§Ù‹ Ø¨Ù†Ø³Ø¨Ø© 100%** Ù„Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµÙŠØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„.
        **Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµØ§Ø±Ù…Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© (Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø¨ØªØ§ØªØ§Ù‹ - Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø³ÙŠØªØ­ÙˆÙ„ Ø¥Ù„Ù‰ ØµÙˆØª):**
        1. **Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„ØªØ§Ù… Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠ (ØµÙˆØªÙŠ):** ÙŠØ¬Ø¨ ØªØ´ÙƒÙŠÙ„ **ÙƒÙ„ Ø­Ø±Ù Ù…ØªØ­Ø±Ùƒ** ÙÙŠ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ ÙÙ‚Ø·: **Ø§Ù„ÙØªØ­Ø©ØŒ Ø§Ù„Ø¶Ù…Ø©ØŒ Ø§Ù„ÙƒØ³Ø±Ø©ØŒ Ø£Ùˆ Ø§Ù„Ø´Ø¯Ø© (Ù…Ø¹ Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„ØªØ§Ø¨Ø¹Ø©)**. Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ§Ù…Ø§Ù‹ 100% Ù„Ø¶Ù…Ø§Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ø·Ù‚ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ø±Ù ØºÙŠØ± Ø³Ø§ÙƒÙ†ØŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­Ù…Ù„ Ø­Ø±ÙƒØ©.
        2. **Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø®Ø§Ù… ÙÙ‚Ø·:** Ø§Ù„Ù†Ø§ØªØ¬ Ù‡Ùˆ **Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ´ÙƒÙÙ‘Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„Ø®Ø§Ù…**ØŒ Ø¯ÙˆÙ† Ø£ÙŠ ÙƒÙ„Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©ØŒ Ù…Ù‚Ø¯Ù…Ø§ØªØŒ Ø´Ø±ÙˆØ­Ø§ØªØŒ Ø£Ùˆ ØªØ±Ù‚ÙŠÙ… Ù…ØªØ³Ù„Ø³Ù„.
        3. **Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙØ§ØµÙ„:** ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ **Ø¥Ù„Ø²Ø§Ù…ÙŠØ§Ù‹** Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨ÙØ§ØµÙ„ **' | '** Ø¨ÙŠÙ† ÙƒÙ„ Ø¬Ù…Ù„Ø© Ù…Ø´ÙƒÙ„Ø© Ù„ØªÙØµÙ„ Ø¨ÙŠÙ†Ù‡Ø§. Ù„Ø§ ØªØºÙŠØ± Ø§Ù„ÙØ§ØµÙ„ Ø£Ùˆ ØªØ­Ø°ÙÙ‡.
        4. **Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ:** ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙŠØ¶Ù…Ù† Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø¹Ù†Ø¯ Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø­Ø±Ùƒ ØµÙˆØªÙŠ (TTS).
        5. Ø´ÙƒÙÙ„ Ø¨Ù…Ù†Ø·Ù‚ Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆÙ…ÙˆÙ‚Ø¹Ù‡Ø§ Ø¨Ù…Ù†Ø·Ù‚ ÙˆØ´ÙƒÙ„ Ø¨ Ø§Ù„Ø¶Ù…Ø© ÙˆØ§Ù„ÙØªØ­Ø© ÙˆØ§Ù„ÙƒØ³Ø±Ø© ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ØµÙˆØª ÙˆÙˆÙŠÙ†ØªØ§ ÙŠÙˆÙ‚Ù ÙˆÙˆÙŠÙ†ØªØ§ ÙŠØªØ­Ø±Ùƒ
         Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ (Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ Ø§Ù„Ù…Ø¹Ù‚ÙˆÙØ©): [{raw_text_to_vocalize}]"""
        try:
            c = genai.Client(api_key=key2)
            re = c.models.generate_content(
                model="gemini-3-flash-preview",
                contents=popo_segment
            )
            summary_content = re.text

            final_vocalized_text = summary_content.replace(" | ", "#").replace("|", "#")

            while "##" in final_vocalized_text:
                final_vocalized_text = final_vocalized_text.replace("##", "#")

            self.vecalized_script = final_vocalized_text
            print("\nØ§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù…ÙØ´ÙƒÙÙ‘Ù„ Ø§Ù„Ù…ÙÙ‚Ø³ÙÙ‘Ù… Ø¨Ù€ #: " + final_vocalized_text + "\n")
            return final_vocalized_text

        except Exception as e:
            raise Exception(f"ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ Ø¹Ø¨Ø± Ollama: {e}")

class audio_clips :
    def __init__(self, text):
        self.text = text

    def clip(self) :
        audio_paths = []

        vocalized_segments = [s.strip() for s in self.text.split("#") if s.strip()]
        print(f"ğŸ’¡ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {len(vocalized_segments)}")

        for key, i in enumerate(vocalized_segments) :

            clean_text = i
            print(f"Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ù„Ù„Ù…Ù‚Ø·Ø¹ {key+1}: {clean_text[:50]}...")
            try:
                audio = elevenlabs.text_to_speech.convert(
                    text=clean_text,
                    voice_id="P1bg08DkjqiVEzOn76yG",
                    model_id="eleven_multilingual_v2",
                )
                output_path = f"Audio\\audio{key+1}.mp3"
                save(audio, output_path)
                audio_paths.append(output_path)
            except Exception as e:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù„Ù„Ù…Ù‚Ø·Ø¹ Ø±Ù‚Ù… {key+1}: {e}")
                
        return audio_paths

class pictures :
    def __init__(self, script_texts):
        self.script_texts = script_texts
        self.output_dir = "Images"
        self.image_size_params = "width=720&height=1280&nologo=true"

    def generate_image_for_prompt(self, prompt_text, part):
        popo = f"""Translate to a short English prompt: [{prompt_text}]. 
                Keywords: Cinematic, Photorealistic, No text.
                Whatever the case, do not write on the image in any language, and ensure the image makes sense in relation to the sentence. Be careful to use logic and provide a clear explanation to the image creator to ensure it is appropriate."""
        c = genai.Client(api_key=key2)
        re = c.models.generate_content(
            model="gemini-3-flash-preview",
            contents=popo
        )
        summary_content = re.text
        print(f"Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù„Ù„Ù…Ù‚Ø·Ø¹ {part+1}: {summary_content}\n")

        encoded = quote_plus(summary_content)
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        url = f"https://image.pollinations.ai/prompt/{encoded}?{self.image_size_params}&seed={int(time.time())}"
        MAX_RETRIES = 5

        for attempt in range(MAX_RETRIES):
            try:
                resp = requests.get(url, headers=headers, timeout=60)
                if resp is not None and resp.status_code == 200:
                    final_path = os.path.join(self.output_dir, f"part{part+1}.jpg")
                    with open(final_path, 'wb') as f:
                        f.write(resp.content)
                    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø±Ù‚Ù… {part+1} Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø±Ù‚Ù… {attempt + 1}.")
                    return final_path
                else:
                    print(f"âš ï¸ Ø³ÙŠØ±ÙØ± Ø§Ù„ØµÙˆØ± Ù…Ø´ØºÙˆÙ„.. Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}")
            except Exception as e:
                print(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} ÙØ´Ù„Øª Ù„Ù„Ù…Ù‚Ø·Ø¹ {part+1}: {e}")
            time.sleep(3)
        return None

    def picture(self) :
        generated_paths = []
        for part, prompt in enumerate(tqdm(self.script_texts, desc="Generating images")):
            if prompt:
                path = self.generate_image_for_prompt(prompt, part)
                if path:
                    generated_paths.append(path)
                # else :
                    # raise Exception(f"âŒ ØªÙˆÙ‚Ù! ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø±Ù‚Ù… {part+1}. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø£Ùˆ Ø¬Ø±Ø¨ Ù„Ø§Ø­Ù‚Ø§Ù‹.")
        return generated_paths
# class pictures :
#     def __init__(self, script_texts):
#         self.script_texts = script_texts
#         self.output_dir = "Images"
#         # &model=flux
#         self.image_size_params = "width=720&height=1280&nologo=true"

#     def generate_image_for_prompt(self, prompt_text, part):
#         time.sleep(part * 5)
#         try:
#             popo = f"""Translate this Arabic sentence into a short, powerful English image prompt.
#             Output ONLY the English text.
#             Strict Rules:
#             1. No intro/outro.
#             2. No text, no captions, no letters on image.
#             3. Essential Keywords only: Cinematic, 8k, Photorealistic, dramatic lighting, highly detailed, no text.
#             Sentence: [{prompt_text}]"""
#             c = genai.Client(api_key=key2)
#             re = c.models.generate_content(
#                 model="gemini-3-flash-preview",
#                 contents=popo
#             )
#             summary_content = re.text
#             print(f"Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù„Ù„Ù…Ù‚Ø·Ø¹ {part+1}: {summary_content}\n")

#             encoded = quote_plus(summary_content)
#             import random
#             rand_val = random.randint(1, 1000000)
#             url = f"https://image.pollinations.ai/prompt/{encoded}?{self.image_size_params}&seed={rand_val}&model=flux&cache={rand_val}"
#             MAX_RETRIES = 7

#             for attempt in range(MAX_RETRIES):
#                 try:
#                     resp = requests.get(url, timeout=60)
#                     if resp.status_code == 200 and len(resp.content) > 30000:
#                         final_path = os.path.join(self.output_dir, f"part{part+1}.jpg")
#                         with open(final_path, 'wb') as f:
#                             f.write(resp.content)
#                         print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© {part+1}")
#                         return final_path
#                     else:
#                         print(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…Ø´ØºÙˆÙ„ Ù„Ù„Ù…Ù‚Ø·Ø¹ {part+1}.. Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1}")
#                         time.sleep(6)
#                 except Exception:
#                     time.sleep(6)
#                     print(f"âš ï¸ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} Ù„Ù„Ù…Ù‚Ø·Ø¹ {part+1}")
#                     continue
#             return None
#         except Exception as e:
#             print(f"âŒ Ø®Ø·Ø£ ÙÙ†ÙŠ ÙÙŠ Ø§Ù„Ù…Ù‚Ø·Ø¹ {part+1}: {e}")
#             return None
#     def picture(self) :
#         import concurrent.futures
#         generated_paths = [None] * len(self.script_texts)
#         def do(prompt_idx_tuple) :
#             part, prompt = prompt_idx_tuple
#             return self.generate_image_for_prompt(prompt, part), part
#         print(f"ğŸš€ Ø¬Ø§Ø±ÙŠ Ø·Ù„Ø¨ {len(self.script_texts)} ØµÙˆØ± ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª...")
#         with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
#             tasks = [(i, p) for i, p in enumerate(self.script_texts) if p]
#             future_to_part = {executor.submit(do, task): task[0] for task in tasks}
#             for future in concurrent.futures.as_completed(future_to_part):
#                 path,part_idx = future.result()
#                 if path:
#                     generated_paths[part_idx] = path
#                 else :
#                     print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© {part_idx+1} Ø¨Ø¹Ø¯ ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª.")
#         return [p for p in generated_paths if p is not None]

class final_video() :
    def __init__(self, pictures_paths, script_processor, audio_paths, titel):
        self.script_processor = script_processor
        self.pictures = pictures_paths
        self.unvocalized_texts = self.script_processor.unvocalized_script
        self.audio_paths = audio_paths
        self.titel = titel

    def create_image_clip_with_zoom(self, picture_path, duration, index):
        global FINAL_RESOLUTION, ZOOM_FACTOR
        target_w, target_h = FINAL_RESOLUTION

        try:
            base_image = Image.open(picture_path)
        except Exception as e:
            return None
        w_orig, h_orig = base_image.size
        final_ratio = max(target_w / w_orig, target_h / h_orig)

        if index % 2 == 0:
            start_factor = 1.0
            end_factor = ZOOM_FACTOR
        else:
            start_factor = ZOOM_FACTOR
            end_factor = 1.0
        def make_frame_zoomed(t):
            t_norm = t / duration
            scale_diff = end_factor - start_factor
            scale_factor = start_factor + scale_diff * (t_norm ** 0.4)

            current_ratio = final_ratio * scale_factor
            new_w = int(w_orig * current_ratio)
            new_h = int(h_orig * current_ratio)

            resampling_method = Image.Resampling.BILINEAR if hasattr(Image, 'Resampling') else Image.BILINEAR
            resized_image = base_image.resize((new_w, new_h), resampling_method)
            x_crop = (new_w - target_w) // 2
            y_crop = (new_h - target_h) // 2

            cropped_image = resized_image.crop(
                (x_crop, y_crop, x_crop + target_w, y_crop + target_h)
            )

            return np.array(cropped_image.convert('RGB'))

        return VideoClip(make_frame_zoomed, duration=duration).set_fps(24)

    def w(self) :
        global FINAL_RESOLUTION, ZOOM_FACTOR, FONT_PATH

        num_texts = len(self.unvocalized_texts)
        num_audio = len(self.audio_paths)

        if num_texts == 0 or num_audio == 0 or len(self.pictures) == 0:
            raise Exception("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†ØµÙˆØµ Ø£Ùˆ Ø£ØµÙˆØ§Øª Ø£Ùˆ ØµÙˆØ± Ù…ØªØ§Ø­Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹. ÙØ´Ù„ Ø­Ø±Ø¬.")

        num_clips = min(num_texts, num_audio, len(self.pictures))
        print(f"ğŸ’¡ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {num_clips} Ù…Ù‚Ø·Ø¹ ÙÙŠØ¯ÙŠÙˆ (Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØµÙˆØµ = {num_texts}ØŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙˆØ§Øª = {num_audio}ØŒ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± = {len(self.pictures)}).")

        pictures_to_use = self.pictures[:num_clips]
        texts_to_use = self.unvocalized_texts[:num_clips]
        audio_paths_to_use = self.audio_paths[:num_clips]

        clips = []
        audio_segments = []

        for index, (picture, text_content_raw, audio_path) in enumerate(zip(pictures_to_use, texts_to_use, audio_paths_to_use)) :

            try:
                with AudioFileClip(audio_path) as audio_clip_temp:
                    duration = audio_clip_temp.duration
                print(f"Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù‚Ø·Ø¹ Ø±Ù‚Ù… {index+1} (Ø§Ù„Ù…Ø¯Ø© Ù…Ù† Ø§Ù„ØµÙˆØª: {duration:.2f} Ø«Ø§Ù†ÙŠØ©)...")
                video_clip = self.create_image_clip_with_zoom(picture, duration, index)
                if video_clip is None:
                    continue
                audio_segments.append(AudioFileClip(audio_path))
                words = text_content_raw.split()
                display_text_list = list(words)
                if len(words) <= 4 :
                    split_index = math.ceil(len(words) / 1)
                    display_text_list.insert(split_index, '\n')

                elif len(words) >= 5 and len(words) <= 10 :
                    split_index = math.ceil(len(words) / 2)
                    display_text_list.insert(split_index, '\n')
                else :
                    split_index = 5
                    display_text_list.insert(split_index, '\n')

                display_text = " ".join(display_text_list)
                current_font = FONT_PATH if os.path.exists(FONT_PATH) else "Arial"
                with TextClip(
                    display_text,
                    fontsize=40,
                    color="yellow",
                    method="caption",
                    stroke_color="black",
                    font=current_font,
                    stroke_width=1,
                    size=(FINAL_RESOLUTION[0] * 0.9, None)
                ).set_position(("center", 840)).set_duration(duration) as text_clip:

                    final_clip = CompositeVideoClip([video_clip, text_clip], size=FINAL_RESOLUTION).set_duration(duration)
                    clips.append(final_clip)

                video_clip.close()

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø±Ù‚Ù… {index+1}: {e}")
                if audio_segments: audio_segments.pop().close()
                continue

        if not clips:
            raise Exception("Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠØ¯ÙŠÙˆ ØµØ§Ù„Ø­Ø©. ÙØ´Ù„ Ø­Ø±Ø¬.")

        FADE_DURATION = 1

        try:
            final_video_base = concatenate_videoclips(clips)
            video_audio_base = concatenate_audioclips(audio_segments)

            final_duration = final_video_base.duration
            global_status_label.configure(text="...ğŸ”Š Ø¬Ø§Ø±ÙŠ Ø¯Ù…Ø¬ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØª Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰")

            op = "Sonder(chosic.com).mp3"

            if os.path.exists(op):
                music_clip = AudioFileClip(op).subclip(16).set_duration(final_duration).volumex(0.25)
                combined_audio = CompositeAudioClip([video_audio_base, music_clip])
                final_audio = combined_audio.audio_fadeout(FADE_DURATION).set_duration(final_duration)
            else:
                final_audio = video_audio_base.audio_fadeout(FADE_DURATION)

            final_video_base.audio = final_audio

            final_video_base.write_videofile(
                f"{self.titel}.mp4",
                fps=24,
                codec='libx264',
                preset='ultrafast',
                bitrate='2500k',
                audio_codec='aac',
                threads=4,
                verbose=True,
                remove_temp=True,
                logger='bar'
            )

            # Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø¨Ø¹Ø¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙ‚Ø·
            final_video_base.close()
            video_audio_base.close()
            if os.path.exists(op):
                music_clip.close()

            for clip in clips:
                clip.close()
            for segment in audio_segments:
                segment.close()

        except Exception as e:
            raise Exception(f"ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ø§Ù„ØµÙˆØª: {e}")

        finally:
            pass

        print("\nâœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… Ø­ÙØ¸ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.")
        notification.notify(
            title="ØµØ§Ù†Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ğŸ“¹",
            message="ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­\nØ´ÙƒØ±Ø§Ù‹ Ù„Ùƒ, Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡",
            timeout=10
        )

def final() :
    def task():

        try:
            cleanup_directories()
            lab2.configure(state="disabled")

            if not entr.get():
                global_status_label.configure(text="Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø¯Ø¡")
                lab2.configure(state="normal")
                return
            
            global_status_label.configure(text="...Ø¬Ø§Ø±ÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª")
            scriptj = script_writing(title=entr.get())
            scriptj.script()

            global_status_label.configure(text="...Ø¬Ø§Ø±ÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙˆØªØ´ÙƒÙŠÙ„Ù‡")
            time.sleep(1)
            divided_script = script_division(script_obj=scriptj)
            unvocalized_texts = divided_script.divisio1()
            time.sleep(1)
            vocalized_text = divided_script.division2()

            global_status_label.configure(text="...Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±")
            time.sleep(3)
            picture_creator = pictures(script_texts=unvocalized_texts)
            picture = picture_creator.picture()
            
            global_status_label.configure(text="...Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©")
            audio_creator = audio_clips(text=vocalized_text)
            audio_paths = audio_creator.clip()


            global_status_label.configure(text="...Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØ¯Ù…Ø¬ Ø§Ù„ØµÙˆØª (Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø®Ù„ÙÙŠØ©)")
            final_video(pictures_paths=picture, script_processor=divided_script, audio_paths=audio_paths, titel=entr.get().strip()).w()

            global_status_label.configure(text="ØªÙ… Ø§Ù„Ø¥Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù‚ØµÙŠØ± Ø¨Ù†Ø¬Ø§Ø­")

        except Exception as e:
            global_status_label.configure(text=f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}")
            print(f"Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}")

        finally:
            lab2.configure(state="normal")

    threading.Thread(target=task).start()

global_status_label = ctk.CTkLabel(lolo, font=("Arial", 15), text="Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø¯Ø¡", fg_color="gray20", text_color="white")
global_status_label.pack(side=tk.BOTTOM, fill=tk.X)
entr = ctk.CTkEntry(lolo, font=("Arial", 15), placeholder_text="Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹", justify='right')
entr.pack(pady=14)
lab2 = ctk.CTkButton(lolo, text="Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", font=("Arial", 18, "bold"), command=final)
lab2.pack(pady= 34)
lolo.mainloop()




# moviepy
# proglog
# plyer.platforms.win.notification
# imageio_ffmpeg
# PIL._imagingtk
# PIL._tkinter_finder
# customtkinter

# imageio
# moviepy